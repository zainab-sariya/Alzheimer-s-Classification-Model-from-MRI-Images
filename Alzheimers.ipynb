{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85d8a9c0",
   "metadata": {},
   "source": [
    "# Introduction + Set-up\n",
    "\n",
    "Machine learning has a phenomenal range of application in the health sciences. This tutorial will go over the complete pipeline to build a model that can determine the dementia level of an Alzheimer's patient from their MRI image. This model achieves an a high ROC AUC score.\n",
    "\n",
    "This tutorial highlights the ease of building a CNN using `tf.keras`. Additionally, TensorFlow 2.3 has new features, including easy data loading utilities that were previously not available in TensorFlow 2.2. We'll be seeing how easy data loading is with these additional features.\n",
    "\n",
    "We'll be using a GPU accelerator for this NB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4f04f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
    "    \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115b6e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "IMAGE_SIZE = [176, 208]\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a84ff6e",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "We'll be using a [Kaggle Alzheimer's dataset](https://www.kaggle.com/tourist55/alzheimers-dataset-4-class-of-images) for our tutorial. `tf.keras` has a new preprocessing function that can easily load in images for a directory. In order for this function to work, the data has to be structured in a file directory format.\n",
    "\n",
    "```\n",
    "main_directory/\n",
    "    class1/\n",
    "        class1_images\n",
    "    class2/\n",
    "        class2_images\n",
    "```\n",
    "If you input the `main_directory` into the `tf.keras` function, it will figure out the rest!\n",
    "In our case, the `train` directory is our main directory.\n",
    "\n",
    "We are also specifying a 80:20 split for our training and validation datasets. To learn more about the importance of having a validation split, check out this [lesson](https://developers.google.com/machine-learning/crash-course/validation/another-partition) from Google's Machine Learning Crash Course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d88e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Alzheimer_s Dataset/train\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Alzheimer_s Dataset/train\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d5cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['MildDementia', 'ModerateDementia', 'NonDementia', 'VeryMildDementia']\n",
    "train_ds.class_names = class_names\n",
    "val_ds.class_names = class_names\n",
    "\n",
    "NUM_CLASSES = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33374091",
   "metadata": {},
   "source": [
    "# Visualize the data\n",
    "\n",
    "Now that our data has been easily loaded in, the next step is to visualize our images. This helps us understand what is being used as an input for our model. It also serves as a check to see if our images have been loaded in correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d6129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(train_ds.class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92ac272",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Because we are working with categorical and noncontinuous data, we want to convert our model into one-hot encodings. One-hot encodings are a way for the model to understand that we're looking at categorial instead of continuous data. Transforming features so that they'll be more understandable is called feature engineering. Learn more about feature engineering [here](https://developers.google.com/machine-learning/crash-course/representation/feature-engineering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af631b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_label(image, label):\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(one_hot_label, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(one_hot_label, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46025530",
   "metadata": {},
   "source": [
    "# The following cells make calling images easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ae7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf1da4",
   "metadata": {},
   "source": [
    "# Deciding a Metric\n",
    "\n",
    "The most conventional metric to use is probably accuracy. Accuracy, however, cannot be used for imbalanced datasets. Let's check how many images are in each class for our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25ac042",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IMAGES = []\n",
    "\n",
    "for label in class_names:\n",
    "    dir_name = \"Alzheimer_s Dataset/train/\" + label[:-2] + 'ed'\n",
    "    NUM_IMAGES.append(len([name for name in os.listdir(dir_name)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2329ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f483eaaa",
   "metadata": {},
   "source": [
    "Our dataset is not balanced, so we cannot use accuracy as our metric. For this tutorial, we will be using ROC AUC. Intuitively, ROC AUC gives a score, with higher scores closer to 1 indicating that the different classes can be distinguishable for the model. A lower score closer indicates that the the model cannot distinguish between different classes. A score of 0.5 indicates that the ordering the images is pretty much random. Learn more about ROC AUC [here](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8440f32e",
   "metadata": {},
   "source": [
    "# Build the ML Model\n",
    "\n",
    "We'll be using the same architecture for our model as my [Pneumonia Classification NB](https://www.kaggle.com/amyjang/tensorflow-pneumonia-classification-on-x-rays#4.-Build-the-CNN). Using `tf.keras`, we can easily build up the layers of our CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e31c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(filters):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPool2D()\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b6eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(units, dropout_rate):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(*IMAGE_SIZE, 3)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        \n",
    "        conv_block(32),\n",
    "        conv_block(64),\n",
    "        \n",
    "        conv_block(128),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        conv_block(256),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        dense_block(512, 0.7),\n",
    "        dense_block(128, 0.5),\n",
    "        dense_block(64, 0.3),\n",
    "        \n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54800cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = build_model()\n",
    "\n",
    "    METRICS = [tf.keras.metrics.AUC(name='auc')]\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.losses.CategoricalCrossentropy(),\n",
    "        metrics=METRICS\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05337a3",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "\n",
    "To more efficiently train our model. We will be using callbacks to adjust our learning rate and to stop our model once it converges.\n",
    "\n",
    "The [learning rate](https://developers.google.com/machine-learning/glossary#learning-rate) is a very important hyperparameter in the model. Having a LR that is too high will prevent the model from converging. Having a LR that is too slow will make the process too long. Stopping our model early is one mechanism that prevents overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb862bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 **(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(0.01, 20)\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"alzheimer_model.h5\",\n",
    "                                                    save_best_only=True)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                     restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c467b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler],\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f73e3",
   "metadata": {},
   "source": [
    "# Visualize Model Metrics\n",
    "\n",
    "Let's graph the ROC AUC metric and loss after each epoch for the training and validation data. Although we didn't use a random seed for our notebook, the results may slightly vary, generally the scores for the validataion data is similar, if not better, than the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a71a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['auc', 'loss']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b161c9",
   "metadata": {},
   "source": [
    "# Evaluate the Model\n",
    "\n",
    "Although we used the validatation dataset to continually evaluate the model, we also have a separate testing dataset. Let's prepare the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22904f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test\",\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_ds = test_ds.map(one_hot_label, num_parallel_calls=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2e82dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.evaluate(test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
